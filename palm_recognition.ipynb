{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palm Recognition AI Project Report\n",
    "\n",
    "## Dataset Design and Class Balance\n",
    "\n",
    "The dataset consists of 3 classes (based on actual folders):\n",
    "\n",
    "- **alan**: 15 images\n",
    "- **person 1**: 13 images\n",
    "- **person 2**: 7 images\n",
    "\n",
    "**Note:** To include \"Unknown\" palm detection, add a folder named \"UNKNOWN\" with images. The system uses a confidence threshold for unknown detection.\n",
    "\n",
    "**Justification:** The dataset is currently imbalanced, with 'alan' being the dominant class. This reflects a real-world scenario where the primary user is present most often. However, for robust training, we use data augmentation (resizing/normalization) and validation splits. \n",
    "\n",
    "## Image Size and Preprocessing\n",
    "\n",
    "- **Image Size**: 128x128 pixels.\n",
    "- **Justification**: This size mitigates computational cost while retaining sufficient spatial detail for palm feature extraction. Lower resolutions might lose texture details (lines), while higher resolutions would slow down real-time inference.\n",
    "- **Normalization**: Pixel values are scaled to [0, 1] to ensure model stability.\n",
    "\n",
    "## Ethical and Privacy Considerations\n",
    "\n",
    "- **Bias**: The dataset currently has limited diversity in skin tones and lighting conditions. This may lead to biased performance against underrepresented groups.\n",
    "- **Privacy**: Face data is not explicitly captured, but palm prints are biometric data. In a production system, these images should be encrypted.\n",
    "- **Live Testing**: The system includes a real-time detection module.\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n",
    "- **Primary Metric**: Accuracy (overall correctness).\n",
    "- **Secondary Metrics**: Confusion Matrix and Precision/Recall are used to detect if the model is just predicting the majority class (\"alan\").\n",
    "\n",
    "## Unknown Palm Detection\n",
    "\n",
    "- A confidence threshold (e.g., 0.8) is applied. If the maximum probability is below this, the prediction is rejected as \"Unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to install the necessary libraries into your current kernel\n",
    "%pip install opencv-python numpy matplotlib tensorflow scikit-learn seaborn\n",
    "import os, json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./data set\"\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# Filter only folders that contain images\n",
    "valid_categories = []\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    for entry in os.listdir(DATASET_PATH):\n",
    "        entry_path = os.path.join(DATASET_PATH, entry)\n",
    "        if os.path.isdir(entry_path) and len(os.listdir(entry_path)) > 0:\n",
    "            valid_categories.append(entry)\n",
    "else:\n",
    "    raise FileNotFoundError(\"Dataset directory not found! Make sure './data set' exists.\")\n",
    "\n",
    "# IMPORTANT: Stable class order (prevents wrong label mapping in live testing)\n",
    "categories = sorted(valid_categories)\n",
    "\n",
    "print(f\"Found categories (sorted): {categories}\")\n",
    "\n",
    "if not categories:\n",
    "    raise ValueError(\"No data found! Please run the Data Collection cell above.\")\n",
    "\n",
    "# Save class order for later (live camera cell must load this)\n",
    "with open(\"class_names.json\", \"w\") as f:\n",
    "    json.dump(categories, f)\n",
    "\n",
    "label_dict = {category: i for i, category in enumerate(categories)}\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "print(\"Loading data and checking class balance...\")\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(DATASET_PATH, category)\n",
    "    images = os.listdir(folder_path)\n",
    "    print(f\"Class '{category}': {len(images)} images\")\n",
    "\n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        img = img.astype(\"float32\") / 255.0  # Normalize\n",
    "        data.append(img)\n",
    "        labels.append(label_dict[category])\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels, dtype=\"int32\")\n",
    "\n",
    "print(f\"Data loaded: {data.shape}\")\n",
    "print(f\"Labels loaded: {labels.shape}\")\n",
    "\n",
    "# Train/test split (stratified)\n",
    "X_train, X_test, y_train_raw, y_test_raw = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_categorical(y_train_raw, num_classes=len(categories))\n",
    "y_test  = to_categorical(y_test_raw,  num_classes=len(categories))\n",
    "\n",
    "print(\"✅ X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n",
    "print(\"✅ y_train:\", y_train.shape, \"y_test:\", y_test.shape)\n",
    "print(\"✅ Classes saved to class_names.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Building (FIXED: better stability + matches categories count) ---\n",
    "if 'categories' in locals() and len(categories) > 0:\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(categories), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "else:\n",
    "    raise ValueError(\"Cannot build model - no categories found. Run preprocessing first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training (FIXED: Augmentation + EarlyStopping + Save model) ---\n",
    "if 'X_train' in locals():\n",
    "    # Data augmentation to improve generalisation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.08,\n",
    "        height_shift_range=0.08,\n",
    "        zoom_range=0.10,\n",
    "        brightness_range=(0.8, 1.2),\n",
    "        horizontal_flip=False\n",
    "    )\n",
    "\n",
    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

    from sklearn.utils import class_weight

    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_raw), y=y_train_raw)

    class_weights = {i: class_weights[i] for i in range(len(class_weights))}
    "\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=32),\n",
    "        epochs=25,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    model.save('palm_recognition_model.h5')\n",
    "    print(\"✅ Model saved as palm_recognition_model.h5\")\n",
    "\n",
    "    # Plot Training History\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    raise ValueError(\"X_train not found. Run preprocessing first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation & Confusion Matrix (FIXED: no seaborn needed) ---\n",
    "if 'X_test' in locals():\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_true, y_pred_classes, target_names=categories))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.xticks(range(len(categories)), categories, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(len(categories)), categories)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    raise ValueError(\"X_test not found. Run preprocessing + training first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Real-time Prediction (FIXED: loads class_names.json + confidence threshold) ---\n",
    "IMG_SIZE = 128\n",
    "CONFIDENCE_THRESHOLD = 0.8  # Confidence threshold for unknown detection\n",
    "\n",
    "MODEL_PATH = \"palm_recognition_model.h5\"\n",
    "CLASS_PATH = \"class_names.json\"\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(\"Model file not found. Please run training first.\")\n",
    "\n",
    "if not os.path.exists(CLASS_PATH):\n",
    "    raise FileNotFoundError(\"class_names.json not found. Run preprocessing cell that saves class order.\")\n",
    "\n",
    "# Load model + stable class list\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "with open(CLASS_PATH, \"r\") as f:\n",
    "    categories = json.load(f)\n",
    "\n",
    "category_map = {i: cat for i, cat in enumerate(categories)}\n",
    "print(\"✅ Loaded classes:\", categories)\n",
    "\n",
    "# Check camera availability\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Camera not available. Please check camera connection.\")\n",
    "\n",
    "print(\"Starting Real-time Recognition... Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocess frame\n",
    "    img = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "    img = np.expand_dims(img, axis=0).astype(\"float32\") / 255.0\n",
    "\n",
    "    # Predict\n",
    "    pred = model.predict(img, verbose=0)[0]\n",
    "    class_idx = int(np.argmax(pred))\n",
    "    confidence = float(np.max(pred))\n",
    "    predicted_label = category_map.get(class_idx, \"Unknown\")\n",
    "\n",
    "    # Unknown decision: if confidence below threshold -> Unknown\n",
    "    if confidence < CONFIDENCE_THRESHOLD:\n",
    "        label = \"Unknown\"\n",
    "        color = (0, 0, 255)  # Red\n",
    "    else:\n",
    "        label = predicted_label\n",
    "        color = (0, 255, 0)  # Green\n",
    "\n",
    "    text = f\"{label}: {confidence:.2f}\"\n",
    "    cv2.putText(frame, text, (10, 35), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    cv2.imshow(\"Palm Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
